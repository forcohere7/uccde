{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Underwater Image Enhancement: Colour Correction and Detail Enhancement using Hybrid Real-ESRGAN\n",
        "\n",
        "This notebook implements a pipeline for enhancing underwater images by combining **color correction techniques** with **Real-ESRGAN** for super-resolution. The process addresses common underwater imaging issues such as color distortion, low contrast, and loss of detail due to water attenuation. The pipeline consists of two main stages:\n",
        "\n",
        "1. **Color Correction**: Adjusts color balance and compensates for underwater-specific distortions using techniques like guided filtering and LAB color space stretching.\n",
        "2. **Detail Enhancement**: Applies Real-ESRGAN, a state-of-the-art super-resolution model, to enhance image details and sharpness.\n",
        "\n",
        "Additionally, the notebook includes a **performance evaluation** step to compute metrics (PSNR and MSE) by comparing processed images with reference images.\n",
        "\n",
        "## Objectives\n",
        "- Correct color casts in underwater images caused by light absorption and scattering.\n",
        "- Enhance image contrast and detail using advanced image processing and deep learning techniques.\n",
        "- Evaluate the quality of enhanced images using quantitative metrics.\n",
        "\n",
        "## Prerequisites\n",
        "- Google Colab with GPU support (T4 or better recommended).\n",
        "- Input images or videos in the `input/` directory.\n",
        "- Reference images in the `reference/` directory for evaluation.\n",
        "- Pre-trained Real-ESRGAN model weights (`net_g_5000.pth`) uploaded to Colab.\n",
        "\n",
        "Let's proceed with the implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CondaValueError: Environment names cannot contain path separators\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda env create -f environment.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "This section installs all the required system dependencies and Python libraries for image processing, video handling, and Real-ESRGAN-based super-resolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 https://packages.microsoft.com/repos/microsoft-ubuntu-noble-prod noble InRelease\n",
            "Hit:2 https://dl.yarnpkg.com/debian stable InRelease\n",
            "Hit:3 https://repo.anaconda.com/pkgs/misc/debrepo/conda stable InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu noble InRelease                   \u001b[0m\u001b[33m\u001b[33m\n",
            "Hit:5 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu noble-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu noble-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Hit:1 https://dl.yarnpkg.com/debian stable InRelease\n",
            "Hit:2 https://repo.anaconda.com/pkgs/misc/debrepo/conda stable InRelease       \u001b[0m\u001b[33m\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu noble InRelease                         \u001b[0m3m\n",
            "Hit:4 http://security.ubuntu.com/ubuntu noble-security InRelease    \u001b[0m       \u001b[33m\n",
            "Get:5 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]3m\n",
            "Hit:6 https://packages.microsoft.com/repos/microsoft-ubuntu-noble-prod noble InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu noble-backports InRelease33m\u001b[33m\u001b[33m\n",
            "Fetched 126 kB in 2s (62.9 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1 is already the newest version (1.7.0-1build1).\n",
            "ffmpeg is already the newest version (7:6.1.1-3ubuntu5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!sudo apt update && sudo apt install -y libgl1 ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q basicsr facexlib gfpgan numpy opencv-python Pillow torch torchvision tqdm realesrgan natsort scipy scikit-image ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda config --add channels defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda env export > environment.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Sync up environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda config --add channels defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 25.5.0\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "Installing pip dependencies: | Ran pip subprocess with arguments:\n",
            "['/opt/conda/envs/conda/bin/python', '-m', 'pip', 'install', '-U', '-r', '/workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting absl-py==2.3.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 1))\n",
            "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting addict==2.4.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 2))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting basicsr==1.4.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3))\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting facexlib==0.3.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 4))\n",
            "  Downloading facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting ffmpeg-python==0.2.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 5))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting filterpy==1.4.5 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting future==1.0.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 7))\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting gfpgan==1.3.8 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 8))\n",
            "  Downloading gfpgan-1.3.8-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting grpcio==1.73.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 9))\n",
            "  Downloading grpcio-1.73.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting imageio==2.37.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 10))\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting lazy-loader==0.4 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 11))\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting llvmlite==0.44.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 12))\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting lmdb==1.6.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 13))\n",
            "  Downloading lmdb-1.6.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting markdown==3.8.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 14))\n",
            "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting natsort==8.4.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 15))\n",
            "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting numba==0.61.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 16))\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 17))\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 18))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 19))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 20))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 21))\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 22))\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 23))\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 24))\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 25))\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 26))\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 27))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 28))\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 29))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 30))\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting opencv-python==4.11.0.86 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 31))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting protobuf==6.31.1 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 32))\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting realesrgan==0.3.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 33))\n",
            "  Downloading realesrgan-0.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting scikit-image==0.25.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 34))\n",
            "  Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tb-nightly==2.20.0a20250622 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 35))\n",
            "  Downloading tb_nightly-2.20.0a20250622-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorboard-data-server==0.7.2 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 36))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tifffile==2025.6.11 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 37))\n",
            "  Downloading tifffile-2025.6.11-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting torch==2.7.1 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38))\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision==0.22.1 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 39))\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting tqdm==4.67.1 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 40))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting triton==3.3.1 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 41))\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting werkzeug==3.1.3 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 42))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting yapf==0.43.0 (from -r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 43))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (2.2.6)\n",
            "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (from filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (3.10.3)\n",
            "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from lazy-loader==0.4->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 11)) (25.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-image==0.25.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 34)) (3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from tb-nightly==2.20.0a20250622->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 35)) (80.9.0)\n",
            "Requirement already satisfied: six>1.9 in /home/codespace/.local/lib/python3.12/site-packages (from tb-nightly==2.20.0a20250622->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 35)) (1.17.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38)) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38)) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38)) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug==3.1.3->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 42)) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from yapf==0.43.0->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 43)) (4.3.8)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 38)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->filterpy==1.4.5->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->basicsr==1.4.2->-r /workspaces/uccde/evaluation/condaenv.auojpcqy.requirements.txt (line 3)) (2025.4.26)\n",
            "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\n",
            "Downloading grpcio-1.73.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.6.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
            "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "Downloading realesrgan-0.3.0-py3-none-any.whl (26 kB)\n",
            "Downloading scikit_image-0.25.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tb_nightly-2.20.0a20250622-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2025.6.11-py3-none-any.whl (230 kB)\n",
            "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "Building wheels for collected packages: basicsr, filterpy\n",
            "  Building wheel for basicsr (setup.py): started\n",
            "  Building wheel for basicsr (setup.py): finished with status 'done'\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214909 sha256=593505ff8653a38b55f07b7017a18f08c7c4d807ec815ee384b36d6d56fc3c37\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/9a/e3/e4/58f29bfabb622dd40b6d9839318ce5bf092062b81ca3aa19ea\n",
            "  Building wheel for filterpy (setup.py): started\n",
            "  Building wheel for filterpy (setup.py): finished with status 'done'\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110545 sha256=78e6c8dd8eca897027da7d5942ba9b3df338b436480017d574b1d12e44ad8b83\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built basicsr filterpy\n",
            "Installing collected packages: nvidia-cusparselt-cu12, lmdb, addict, yapf, werkzeug, triton, tqdm, tifffile, tensorboard-data-server, protobuf, opencv-python, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, natsort, markdown, llvmlite, lazy-loader, imageio, grpcio, future, absl-py, tb-nightly, scikit-image, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, ffmpeg-python, nvidia-cusolver-cu12, filterpy, torch, torchvision, facexlib, basicsr, gfpgan, realesrgan\n",
            "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m35/43\u001b[0m [nvidia-cusolver-cu12]2]\n",
            "\u001b[2K    Found existing installation: torch 2.7.0+cpu0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m35/43\u001b[0m [nvidia-cusolver-cu12]\n",
            "\u001b[2K    Uninstalling torch-2.7.0+cpu:━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m37/43\u001b[0m [torch]olver-cu12]\n",
            "\u001b[2K      Successfully uninstalled torch-2.7.0+cpu\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m37/43\u001b[0m [torch]\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/43\u001b[0m [realesrgan]3\u001b[0m [basicsr]]on]\n",
            "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.0 addict-2.4.0 basicsr-1.4.2 facexlib-0.3.0 ffmpeg-python-0.2.0 filterpy-1.4.5 future-1.0.0 gfpgan-1.3.8 grpcio-1.73.0 imageio-2.37.0 lazy-loader-0.4 llvmlite-0.44.0 lmdb-1.6.2 markdown-3.8.2 natsort-8.4.0 numba-0.61.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opencv-python-4.11.0.86 protobuf-6.31.1 realesrgan-0.3.0 scikit-image-0.25.2 tb-nightly-2.20.0a20250622 tensorboard-data-server-0.7.2 tifffile-2025.6.11 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 triton-3.3.1 werkzeug-3.1.3 yapf-0.43.0\n",
            "\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate conda\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda env create -f environment.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Fix Dependency Issues\n",
        "\n",
        "The `basicsr` library has a known import issue with `torchvision`. This script corrects the import statement in the `degradations.py` file to ensure compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: basicsr\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip show basicsr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting dependency-fix.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile dependency-fix.sh\n",
        "#!/bin/bash\n",
        "# Fix torchvision import in basicsr/data/degradations.py using relative path\n",
        "sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' ../.conda/lib/python3.12/site-packages/basicsr/data/degradations.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If not using conda\n",
        "# %%writefile dependency-fix.sh\n",
        "# #!/bin/bash\n",
        "# # Fix torchvision import in basicsr/data/degradations.py\n",
        "# sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/python/3.12.1/lib/python3.12/site-packages/basicsr/data/degradations.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "!chmod +x dependency-fix.sh\n",
        "!./dependency-fix.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Color Correction Implementation\n",
        "\n",
        "This section defines the core classes and functions for underwater image color correction. The `GuidedFilter` class implements a guided filter for refining transmission maps, while the `ColourCorrection` class handles color balancing and depth map estimation. Additional functions enhance contrast and color through histogram stretching and LAB color space adjustments.\n",
        "\n",
        "Key features:\n",
        "- **Guided Filter**: Smooths transmission maps while preserving edges.\n",
        "- **Color Compensation**: Adjusts red and blue channels to counter underwater color casts.\n",
        "- **Depth Map Estimation**: Models light attenuation to estimate scene depth.\n",
        "- **LAB Stretching**: Enhances luminance and color balance in the LAB color space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import datetime\n",
        "import numpy as np\n",
        "import natsort\n",
        "import math\n",
        "from scipy import stats\n",
        "from skimage.color import rgb2hsv, hsv2rgb, rgb2lab, lab2rgb\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from functools import partial\n",
        "import ffmpeg\n",
        "\n",
        "# Configuration settings\n",
        "CONFIG = {\n",
        "    'input_dir': 'input',\n",
        "    'output_dir': 'output-ip',\n",
        "    'block_size': 9,\n",
        "    'gimfilt_radius': 30,\n",
        "    'eps': 1e-2,\n",
        "    'rb_compensation_flag': 0,  # 0: Compensate both Red and Blue, 1: Compensate only Red\n",
        "    'enhancement_strength': 0.6,  # Control enhancement intensity\n",
        "    'video_extensions': ['.mp4', '.avi', '.mov'],  # Supported video formats\n",
        "    'output_video_fps': 30,  # Default output video frame rate\n",
        "    'output_video_codec': 'mp4v',  # Codec for output video\n",
        "    'temp_video_path': 'temp_output.mp4',  # Temporary video file without audio\n",
        "}\n",
        "\n",
        "# Set numpy to ignore overflow warnings\n",
        "np.seterr(over='ignore')\n",
        "\n",
        "# Guided Filter Class\n",
        "class GuidedFilter:\n",
        "    \"\"\"Guided filter for image processing to refine transmission maps while preserving edges.\"\"\"\n",
        "    def __init__(self, input_image, radius=5, epsilon=0.4):\n",
        "        self._radius = 2 * radius + 1\n",
        "        self._epsilon = epsilon\n",
        "        self._input_image = self._to_float_img(input_image)\n",
        "        self._init_filter()\n",
        "\n",
        "    def _to_float_img(self, img):\n",
        "        if img.dtype == np.float32:\n",
        "            return img\n",
        "        return img.astype(np.float32) / 255.0\n",
        "\n",
        "    def _init_filter(self):\n",
        "        img = self._input_image\n",
        "        r = self._radius\n",
        "        eps = self._epsilon\n",
        "        ir, ig, ib = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
        "        ksize = (r, r)\n",
        "        self._ir_mean = cv2.blur(ir, ksize)\n",
        "        self._ig_mean = cv2.blur(ig, ksize)\n",
        "        self._ib_mean = cv2.blur(ib, ksize)\n",
        "        irr = cv2.blur(ir * ir, ksize) - self._ir_mean ** 2 + eps\n",
        "        irg = cv2.blur(ir * ig, ksize) - self._ir_mean * self._ig_mean\n",
        "        irb = cv2.blur(ir * ib, ksize) - self._ir_mean * self._ib_mean\n",
        "        igg = cv2.blur(ig * ig, ksize) - self._ig_mean ** 2 + eps\n",
        "        igb = cv2.blur(ig * ib, ksize) - self._ig_mean * self._ib_mean\n",
        "        ibb = cv2.blur(ib * ib, ksize) - self._ib_mean ** 2 + eps\n",
        "        det = irr * (igg * ibb - igb * igb) - irg * (irg * ibb - igb * irb) + irb * (irg * igb - igg * irb)\n",
        "        self._irr_inv = (igg * ibb - igb * igb) / det\n",
        "        self._irg_inv = -(irg * ibb - igb * irb) / det\n",
        "        self._irb_inv = (irg * igb - igg * irb) / det\n",
        "        self._igg_inv = (irr * ibb - irb * irb) / det\n",
        "        self._igb_inv = -(irr * igb - irb * irg) / det\n",
        "        self._ibb_inv = (irr * igg - irg * irg) / det\n",
        "\n",
        "    def _compute_coefficients(self, input_p):\n",
        "        r = self._radius\n",
        "        ksize = (r, r)\n",
        "        ir, ig, ib = self._input_image[:, :, 0], self._input_image[:, :, 1], self._input_image[:, :, 2]\n",
        "        p_mean = cv2.blur(input_p, ksize)\n",
        "        ipr_cov = cv2.blur(ir * input_p, ksize) - self._ir_mean * p_mean\n",
        "        ipg_cov = cv2.blur(ig * input_p, ksize) - self._ig_mean * p_mean\n",
        "        ipb_cov = cv2.blur(ib * input_p, ksize) - self._ib_mean * p_mean\n",
        "        ar = self._irr_inv * ipr_cov + self._irg_inv * ipg_cov + self._irb_inv * ipb_cov\n",
        "        ag = self._irg_inv * ipr_cov + self._igg_inv * ipg_cov + self._igb_inv * ipb_cov\n",
        "        ab = self._irb_inv * ipr_cov + self._igb_inv * ipg_cov + self._ibb_inv * ipb_cov\n",
        "        b = p_mean - ar * self._ir_mean - ag * self._ig_mean - ab * self._ib_mean\n",
        "        return cv2.blur(ar, ksize), cv2.blur(ag, ksize), cv2.blur(ab, ksize), cv2.blur(b, ksize)\n",
        "\n",
        "    def _compute_output(self, ab):\n",
        "        ar_mean, ag_mean, ab_mean, b_mean = ab\n",
        "        ir, ig, ib = self._input_image[:, :, 0], self._input_image[:, :, 1], self._input_image[:, :, 2]\n",
        "        return ar_mean * ir + ag_mean * ig + ab_mean * ib + b_mean\n",
        "\n",
        "    def filter(self, input_p):\n",
        "        p_32f = self._to_float_img(input_p)\n",
        "        ab = self._compute_coefficients(p_32f)\n",
        "        return self._compute_output(ab)\n",
        "\n",
        "# Colour Correction Class\n",
        "class ColourCorrection:\n",
        "    \"\"\"Handles underwater image color correction by compensating for color casts and estimating depth.\"\"\"\n",
        "    def __init__(self, block_size=CONFIG['block_size'], gimfilt_radius=CONFIG['gimfilt_radius'], eps=CONFIG['eps']):\n",
        "        self.block_size = block_size\n",
        "        self.gimfilt_radius = gimfilt_radius\n",
        "        self.eps = eps\n",
        "\n",
        "    def _compensate_rb(self, image, flag):\n",
        "        b, g, r = cv2.split(image.astype(np.float64))\n",
        "        min_r, max_r = np.min(r), np.max(r)\n",
        "        min_g, max_g = np.min(g), np.max(g)\n",
        "        min_b, max_b = np.min(b), np.max(b)\n",
        "        if max_r == min_r or max_g == min_g or max_b == min_b:\n",
        "            return image\n",
        "        r = (r - min_r) / (max_r - min_r)\n",
        "        g = (g - min_g) / (max_g - min_g)\n",
        "        b = (b - min_b) / (max_b - min_b)\n",
        "        mean_r, mean_g, mean_b = np.mean(r), np.mean(g), np.mean(b)\n",
        "        compensation_strength = 0.4\n",
        "        if flag == 0:\n",
        "            r = (r + compensation_strength * (mean_g - mean_r) * (1 - r) * g) * max_r\n",
        "            b = (b + compensation_strength * (mean_g - mean_b) * (1 - b) * g) * max_b\n",
        "            g = g * max_g\n",
        "        elif flag == 1:\n",
        "            r = (r + compensation_strength * (mean_g - mean_r) * (1 - r) * g) * max_r\n",
        "            g = g * max_g\n",
        "            b = b * max_b\n",
        "        return cv2.merge([np.clip(b, 0, 255).astype(np.uint8),\n",
        "                         np.clip(g, 0, 255).astype(np.uint8),\n",
        "                         np.clip(r, 0, 255).astype(np.uint8)])\n",
        "\n",
        "    def _estimate_background_light(self, img, depth_map):\n",
        "        img = img.astype(np.float32) / 255.0 if img.dtype == np.uint8 else img\n",
        "        height, width = img.shape[:2]\n",
        "        n_bright = int(np.ceil(0.001 * height * width))\n",
        "        indices = np.argpartition(depth_map.ravel(), -n_bright)[-n_bright:]\n",
        "        candidates = img.reshape(-1, 3)[indices]\n",
        "        magnitudes = np.linalg.norm(candidates, axis=1)\n",
        "        sorted_indices = np.argsort(magnitudes)[::-1]\n",
        "        top_n = 10\n",
        "        top_candidates = candidates[sorted_indices[:top_n]]\n",
        "        atmospheric_light = np.mean(top_candidates, axis=0) * 255.0\n",
        "        return atmospheric_light\n",
        "\n",
        "    def _compute_depth_map(self, img):\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        x_1 = np.maximum(img[:, :, 0], img[:, :, 1])\n",
        "        x_2 = img[:, :, 2]\n",
        "        return 0.51157954 + 0.50516165 * x_1 - 0.90511117 * x_2\n",
        "\n",
        "    def _compute_min_depth(self, img, background_light):\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "        background_light = background_light / 255.0\n",
        "        max_values = np.max(np.abs(img - background_light), axis=(0, 1)) / np.maximum(background_light, 1 - background_light)\n",
        "        return 1 - np.max(max_values)\n",
        "\n",
        "    def _global_stretching_depth(self, img_l):\n",
        "        flat = img_l.ravel()\n",
        "        indices = np.argsort(flat)\n",
        "        i_min, i_max = flat[indices[len(flat)//1000]], flat[indices[-len(flat)//1000]]\n",
        "        result = np.clip((img_l - i_min) / (i_max - i_min + 1e-10), 0, 1)\n",
        "        return cv2.GaussianBlur(result, (3, 3), 0.5)\n",
        "\n",
        "    def _get_rgb_transmission(self, depth_map):\n",
        "        return 0.98 ** depth_map, 0.97 ** depth_map, 0.88 ** depth_map\n",
        "\n",
        "    def _refine_transmission_map(self, transmission_b, transmission_g, transmission_r, img):\n",
        "        guided_filter = GuidedFilter(img, self.gimfilt_radius, self.eps)\n",
        "        transmission = np.stack([\n",
        "            guided_filter.filter(transmission_b),\n",
        "            guided_filter.filter(transmission_g),\n",
        "            guided_filter.filter(transmission_r)\n",
        "        ], axis=-1)\n",
        "        return transmission\n",
        "\n",
        "    def _compute_scene_radiance(self, img, transmission, atmospheric_light):\n",
        "        img = img.astype(np.float32)\n",
        "        min_transmission = 0.2\n",
        "        transmission = np.maximum(transmission, min_transmission)\n",
        "        scene_radiance = (img - atmospheric_light) / transmission + atmospheric_light\n",
        "        return np.clip(scene_radiance, 0, 255).astype(np.uint8)\n",
        "\n",
        "    def process(self, img, rb_compensation_flag=CONFIG['rb_compensation_flag']):\n",
        "        img_compensated = self._compensate_rb(img, rb_compensation_flag)\n",
        "        depth_map = self._compute_depth_map(img_compensated)\n",
        "        depth_map = self._global_stretching_depth(depth_map)\n",
        "        guided_filter = GuidedFilter(img_compensated, self.gimfilt_radius, self.eps)\n",
        "        refined_depth_map = guided_filter.filter(depth_map)\n",
        "        refined_depth_map = np.clip(refined_depth_map, 0, 1)\n",
        "        atmospheric_light = self._estimate_background_light(img_compensated, depth_map)\n",
        "        d_0 = self._compute_min_depth(img_compensated, atmospheric_light)\n",
        "        d_f = 6 * (depth_map + d_0)\n",
        "        transmission_b, transmission_g, transmission_r = self._get_rgb_transmission(d_f)\n",
        "        transmission = self._refine_transmission_map(transmission_b, transmission_g, transmission_r, img_compensated)\n",
        "        return self._compute_scene_radiance(img_compensated, transmission, atmospheric_light)\n",
        "\n",
        "# Image Enhancement Functions\n",
        "def cal_equalisation(img, ratio):\n",
        "    return np.clip(img * ratio, 0, 255)\n",
        "\n",
        "def rgb_equalisation(img):\n",
        "    img = img.astype(np.float32)\n",
        "    current_mean = np.mean(img, axis=(0, 1))\n",
        "    target_mean = 140\n",
        "    ratio = target_mean / (current_mean + 1e-10)\n",
        "    ratio = np.clip(ratio, 0.8, 1.2)\n",
        "    return cal_equalisation(img, ratio)\n",
        "\n",
        "def stretch_range(r_array, height, width):\n",
        "    flat = r_array.ravel()\n",
        "    mode = stats.mode(flat, keepdims=True).mode[0] if flat.size > 0 else np.median(flat)\n",
        "    mode_indices = np.where(flat == mode)[0]\n",
        "    mode_index_before = mode_indices[0] if mode_indices.size > 0 else len(flat) // 2\n",
        "    dr_min = (1 - 0.755) * mode\n",
        "    max_index = min(len(flat) - 1, len(flat) - int((len(flat) - mode_index_before) * 0.01))\n",
        "    sr_max = np.sort(flat)[max_index]\n",
        "    return dr_min, sr_max, mode\n",
        "\n",
        "def global_stretching_ab(a, height, width):\n",
        "    return a * (1.05 ** (1 - np.abs(a / 128)))\n",
        "\n",
        "def basic_stretching(img):\n",
        "    img = img.astype(np.float64)\n",
        "    min_vals = np.percentile(img, 2, axis=(0,1))\n",
        "    max_vals = np.percentile(img, 98, axis=(0,1))\n",
        "    range_vals = max_vals - min_vals\n",
        "    min_range = 50\n",
        "    mask = range_vals < min_range\n",
        "    max_vals[mask] = min_vals[mask] + min_range\n",
        "    img = np.clip((img - min_vals) * 255 / (max_vals - min_vals + 1e-10), 0, 255)\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "def global_stretching_luminance(img_l, height, width):\n",
        "    flat = img_l.ravel()\n",
        "    indices = np.argsort(flat)\n",
        "    i_min, i_max = flat[indices[len(flat)//50]], flat[indices[-len(flat)//50]]\n",
        "    if i_max == i_min:\n",
        "        i_min, i_max = flat.min(), flat.max()\n",
        "        if i_max == i_min:\n",
        "            return img_l\n",
        "    return np.clip((img_l - i_min) * 95 / (i_max - i_min + 1e-10), 0, 100)\n",
        "\n",
        "def lab_stretching(scene_radiance):\n",
        "    scene_radiance = np.clip(scene_radiance, 0, 255).astype(np.uint8)\n",
        "    original = scene_radiance.copy()\n",
        "    img_lab = rgb2lab(scene_radiance)\n",
        "    l, a, b = img_lab[:, :, 0], img_lab[:, :, 1], img_lab[:, :, 2]\n",
        "    img_lab[:, :, 0] = global_stretching_luminance(l, *scene_radiance.shape[:2])\n",
        "    img_lab[:, :, 1] = global_stretching_ab(a, *scene_radiance.shape[:2])\n",
        "    img_lab[:, :, 2] = global_stretching_ab(b, *scene_radiance.shape[:2])\n",
        "    enhanced = lab2rgb(img_lab) * 255\n",
        "    blend_factor = CONFIG['enhancement_strength']\n",
        "    result = blend_factor * enhanced + (1 - blend_factor) * original\n",
        "    return result\n",
        "\n",
        "def global_stretching_advanced(r_array, height, width, lambda_val, k_val):\n",
        "    flat = r_array.ravel()\n",
        "    indices = np.argsort(flat)\n",
        "    i_min, i_max = flat[indices[len(flat)//100]], flat[indices[-len(flat)//100]]\n",
        "    dr_min, sr_max, mode = stretch_range(r_array, height, width)\n",
        "    t_n = lambda_val ** 2\n",
        "    o_max_left = sr_max * t_n * k_val / mode\n",
        "    o_max_right = 255 * t_n * k_val / mode\n",
        "    dif = o_max_right - o_max_left\n",
        "    if dif >= 1:\n",
        "        indices = np.arange(1, int(dif) + 1)\n",
        "        sum_val = np.sum((1.326 + indices) * mode / (t_n * k_val))\n",
        "        dr_max = sum_val / int(dif)\n",
        "        p_out = np.where(r_array < i_min, (r_array - i_min) * (dr_min / i_min) + i_min,\n",
        "                         np.where(r_array > i_max, (r_array - dr_max) * (dr_max / i_max) + i_max,\n",
        "                                  ((r_array - i_min) * (255 - i_min) / (i_max - i_min) + i_min)))\n",
        "    else:\n",
        "        p_out = np.where(r_array < i_min, (r_array - r_array.min()) * (dr_min / r_array.min()) + r_array.min(),\n",
        "                         ((r_array - i_min) * (255 - dr_min) / (i_max - i_min) + dr_min))\n",
        "    return p_out\n",
        "\n",
        "def relative_stretching(scene_radiance, height, width):\n",
        "    scene_radiance = scene_radiance.astype(np.float64)\n",
        "    scene_radiance[:, :, 0] = global_stretching_advanced(scene_radiance[:, :, 0], height, width, 0.98, 1.1)\n",
        "    scene_radiance[:, :, 1] = global_stretching_advanced(scene_radiance[:, :, 1], height, width, 0.97, 1.1)\n",
        "    scene_radiance[:, :, 2] = global_stretching_advanced(scene_radiance[:, :, 2], height, width, 0.88, 0.9)\n",
        "    return scene_radiance\n",
        "\n",
        "def image_enhancement(scene_radiance):\n",
        "    if scene_radiance.shape[2] == 3:\n",
        "        scene_radiance = cv2.cvtColor(scene_radiance, cv2.COLOR_BGR2RGB)\n",
        "    if np.max(scene_radiance) == np.min(scene_radiance):\n",
        "        return scene_radiance\n",
        "    original = scene_radiance.copy()\n",
        "    scene_radiance = scene_radiance.astype(np.float64)\n",
        "    scene_radiance = basic_stretching(scene_radiance)\n",
        "    scene_radiance = lab_stretching(scene_radiance)\n",
        "    final_blend = 0.8\n",
        "    result = final_blend * scene_radiance + (1 - final_blend) * original\n",
        "    return np.clip(result, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Processing Functions\n",
        "def process_image(file, input_dir=CONFIG['input_dir'], output_dir=CONFIG['output_dir']):\n",
        "    file_path = os.path.join(input_dir, file)\n",
        "    base_name, extension = os.path.splitext(file)\n",
        "    print(f'Processing image: {file}')\n",
        "    img = cv2.imread(file_path)\n",
        "    if img is None:\n",
        "        print(f\"Could not read image: {file}\")\n",
        "        return\n",
        "    colour_corrector = ColourCorrection()\n",
        "    print(\"Applying color correction...\")\n",
        "    corrected_img = colour_corrector.process(img)\n",
        "    print(\"Applying image enhancement...\")\n",
        "    final_result = image_enhancement(corrected_img)\n",
        "    final_result_bgr = cv2.cvtColor(final_result, cv2.COLOR_RGB2BGR)\n",
        "    output_file = os.path.join(output_dir, f'{base_name}_ColourCorrected{extension}')\n",
        "    cv2.imwrite(output_file, final_result_bgr)\n",
        "    print(f\"Completed processing image: {file}\")\n",
        "\n",
        "def process_video_frame(frame, colour_corrector):\n",
        "    corrected_frame = colour_corrector.process(frame)\n",
        "    enhanced_frame = image_enhancement(corrected_frame)\n",
        "    return cv2.cvtColor(enhanced_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "def process_video(file, input_dir=CONFIG['input_dir'], output_dir=CONFIG['output_dir']):\n",
        "    file_path = os.path.join(input_dir, file)\n",
        "    prefix = file.split('.')[0]\n",
        "    print(f'Processing video: {file}')\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Could not open video: {file}\")\n",
        "        return\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or CONFIG['output_video_fps']\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    temp_output_path = os.path.join(output_dir, CONFIG['temp_video_path'])\n",
        "    final_output_path = os.path.join(output_dir, f'{prefix}_ColourCorrected.mp4')\n",
        "    fourcc = cv2.VideoWriter_fourcc(*CONFIG['output_video_codec'])\n",
        "    out = cv2.VideoWriter(temp_output_path, fourcc, fps, (width, height))\n",
        "    if not out.isOpened():\n",
        "        print(f\"Could not create output video: {temp_output_path}\")\n",
        "        cap.release()\n",
        "        return\n",
        "    colour_corrector = ColourCorrection()\n",
        "    print(f\"Processing {frame_count} frames...\")\n",
        "    frame_idx = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        print(f\"Processing frame {frame_idx + 1}/{frame_count}\")\n",
        "        processed_frame = process_video_frame(frame, colour_corrector)\n",
        "        out.write(processed_frame)\n",
        "        frame_idx += 1\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    try:\n",
        "        print(f\"Merging original audio into: {final_output_path}\")\n",
        "        input_video = ffmpeg.input(temp_output_path)\n",
        "        input_audio = ffmpeg.input(file_path).audio\n",
        "        output = ffmpeg.output(input_video.video, input_audio, final_output_path, vcodec='copy', acodec='copy', strict='experimental')\n",
        "        ffmpeg.run(output, overwrite_output=True)\n",
        "        print(f\"Completed processing video with audio: {file}\")\n",
        "        if os.path.exists(temp_output_path):\n",
        "            os.remove(temp_output_path)\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"Error merging audio: {e.stderr.decode()}\")\n",
        "        return\n",
        "\n",
        "def main_color_correction():\n",
        "    \"\"\"Main function to process images and videos in the input directory for color correction.\"\"\"\n",
        "    os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
        "    if not os.access(CONFIG['output_dir'], os.W_OK):\n",
        "        print(f\"No write permissions for directory {CONFIG['output_dir']}\")\n",
        "        exit(1)\n",
        "    start_time = datetime.datetime.now()\n",
        "    files = natsort.natsorted(os.listdir(CONFIG['input_dir']))\n",
        "    files = [f for f in files if os.path.isfile(os.path.join(CONFIG['input_dir'], f))]\n",
        "    image_files = [f for f in files if os.path.splitext(f)[1].lower() not in CONFIG['video_extensions']]\n",
        "    video_files = [f for f in files if os.path.splitext(f)[1].lower() in CONFIG['video_extensions']]\n",
        "    if image_files:\n",
        "        print(f\"Processing {len(image_files)} images...\")\n",
        "        with Pool(processes=cpu_count()) as pool:\n",
        "            pool.map(process_image, image_files)\n",
        "    if video_files:\n",
        "        print(f\"Processing {len(video_files)} videos...\")\n",
        "        for video_file in video_files:\n",
        "            process_video(video_file)\n",
        "    print(f'Total processing time: {datetime.datetime.now() - start_time}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run Color Correction\n",
        "\n",
        "Execute the color correction pipeline to process images and videos in the `input/` directory. The processed files are saved in the `output-ip/` directory with a `_ColourCorrected` suffix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 2 images...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing image: file1.png\n",
            "Processing image: file2.png\n",
            "Applying color correction...\n",
            "Applying color correction...\n",
            "Applying image enhancement...\n",
            "Applying image enhancement...\n",
            "Completed processing image: file1.png\n",
            "Completed processing image: file2.png\n",
            "Total processing time: 0:00:02.120687\n"
          ]
        }
      ],
      "source": [
        "main_color_correction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Detail Enhancement with Real-ESRGAN\n",
        "\n",
        "This section applies the **Real-ESRGAN** model to enhance the details of color-corrected images. Real-ESRGAN uses a deep learning-based super-resolution technique to improve image sharpness and clarity.\n",
        "\n",
        "**Note**: Ensure the pre-trained model `net_g_5000.pth` is uploaded to `/content/` before running this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from realesrgan import RealESRGANer\n",
        "\n",
        "def main_esrgan():\n",
        "    # Configuration\n",
        "    input_path = 'output-ip'  # Input folder with color-corrected images\n",
        "    output_path = 'output'  # Output folder for enhanced images\n",
        "    model_name = 'RealESRGAN_x4plus'\n",
        "    model_path = '../RealESRGAN/model/net_g_5000.pth'  # Path to pre-trained model\n",
        "    outscale = 1  # Upsampling scale (1 for no upscaling, just enhancement)\n",
        "    suffix = 'out'  # Suffix for enhanced images\n",
        "    tile = 1000  # Tile size for processing large images\n",
        "\n",
        "    # Validate model name\n",
        "    if model_name != 'RealESRGAN_x4plus':\n",
        "        raise ValueError('This script only supports RealESRGAN_x4plus model')\n",
        "\n",
        "    # Initialize Real-ESRGAN model\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "    netscale = 4\n",
        "    upsampler = RealESRGANer(\n",
        "        scale=netscale,\n",
        "        model_path=model_path,\n",
        "        model=model,\n",
        "        tile=tile,\n",
        "        tile_pad=10,\n",
        "        pre_pad=0,\n",
        "        half=False  # Use fp32 precision\n",
        "    )\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    # Get input files\n",
        "    if os.path.isfile(input_path):\n",
        "        paths = [input_path]\n",
        "    else:\n",
        "        paths = sorted(glob.glob(os.path.join(input_path, '*')))\n",
        "\n",
        "    # Start total execution timer\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Process each image\n",
        "    for idx, path in enumerate(paths):\n",
        "        imgname, extension = os.path.splitext(os.path.basename(path))\n",
        "        print(f'Processing {idx}: {imgname}')\n",
        "\n",
        "        start_time = time.time()\n",
        "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "        if img is None:\n",
        "            print(f'Failed to load image: {path}')\n",
        "            continue\n",
        "\n",
        "        img_mode = 'RGBA' if len(img.shape) == 3 and img.shape[2] == 4 else None\n",
        "        try:\n",
        "            output, _ = upsampler.enhance(img, outscale=outscale)\n",
        "        except RuntimeError as error:\n",
        "            print(f'Error processing {imgname}: {error}')\n",
        "            print('Try reducing tile size if you encounter CUDA out of memory.')\n",
        "            continue\n",
        "\n",
        "        extension = extension[1:] if img_mode != 'RGBA' else 'png'\n",
        "        save_path = os.path.join(output_path, f'{imgname}_{suffix}.{extension}')\n",
        "        cv2.imwrite(save_path, output)\n",
        "\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        print(f'Saved: {save_path}')\n",
        "        print(f'Processing time for {imgname}: {processing_time:.2f} seconds')\n",
        "\n",
        "    total_end_time = time.time()\n",
        "    total_time = total_end_time - total_start_time\n",
        "    print(f'Total execution time: {total_time:.2f} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Real-ESRGAN Enhancement\n",
        "\n",
        "Execute the Real-ESRGAN pipeline to enhance the details of color-corrected images in the `output-ip/` directory. The enhanced images are saved in the `output/` directory with an `_out` suffix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 0: file1_ColourCorrected\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "main_esrgan()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate Image Quality\n",
        "\n",
        "This section evaluates the quality of the processed images by comparing them to reference images in the `reference/` directory. It calculates two metrics:\n",
        "- **PSNR (Peak Signal-to-Noise Ratio)**: Measures the quality of reconstruction (higher is better).\n",
        "- **MSE (Mean Squared Error)**: Measures the average squared difference between images (lower is better).\n",
        "\n",
        "Results are saved to `metrics_output_ip.txt` (for color-corrected images) and `metrics_output.txt` (for Real-ESRGAN enhanced images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from skimage.metrics import peak_signal_noise_ratio, mean_squared_error\n",
        "\n",
        "def compare_images(ref_folder, target_folder, suffix, output_file):\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(f\"{'File':<30} {'PSNR (dB)':<12} {'MSE':<10}\\n\")\n",
        "        f.write('-' * 60 + '\\n')\n",
        "        ref_files = [f for f in os.listdir(ref_folder) if os.path.isfile(os.path.join(ref_folder, f))]\n",
        "        for ref_file in ref_files:\n",
        "            base_name, ext = os.path.splitext(ref_file)\n",
        "            target_file = f\"{base_name}{suffix}{ext}\"\n",
        "            target_path = os.path.join(target_folder, target_file)\n",
        "            if os.path.exists(target_path):\n",
        "                ref_img = cv2.imread(os.path.join(ref_folder, ref_file))\n",
        "                target_img = cv2.imread(target_path)\n",
        "                if ref_img is None or target_img is None:\n",
        "                    f.write(f\"{ref_file:<30} {'Error loading images':<12}\\n\")\n",
        "                    continue\n",
        "                try:\n",
        "                    psnr = peak_signal_noise_ratio(ref_img, target_img)\n",
        "                    mse = mean_squared_error(ref_img, target_img)\n",
        "                    f.write(f\"{ref_file:<30} {psnr:<12.2f} {mse:<10.2f}\\n\")\n",
        "                except Exception as e:\n",
        "                    f.write(f\"{ref_file:<30} {'Error':<12} {str(e):<10}\\n\")\n",
        "            else:\n",
        "                f.write(f\"{ref_file:<30} {'Target not found':<12}\\n\")\n",
        "\n",
        "# Define folder paths and suffixes\n",
        "reference_folder = 'reference/'\n",
        "output_ip_folder = 'output-ip/'\n",
        "output_folder = 'output/'\n",
        "suffix_ip = '_ColourCorrected'\n",
        "suffix_out = '_ColourCorrected_out'\n",
        "\n",
        "# Compare images\n",
        "compare_images(reference_folder, output_ip_folder, suffix_ip, 'metrics_output_ip.txt')\n",
        "compare_images(reference_folder, output_folder, suffix_out, 'metrics_output.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: View Evaluation Results\n",
        "\n",
        "Display the contents of the evaluation metrics files to review the PSNR and MSE values for both color-corrected and Real-ESRGAN-enhanced images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File                           PSNR (dB)    MSE       \n",
            "------------------------------------------------------------\n",
            "file2.png                      20.47        583.55    \n",
            "file1.png                      21.01        515.22    \n",
            "\\n\n",
            "File                           PSNR (dB)    MSE       \n",
            "------------------------------------------------------------\n",
            "file2.png                      20.58        569.05    \n",
            "file1.png                      20.06        640.92    \n"
          ]
        }
      ],
      "source": [
        "!cat metrics_output_ip.txt\n",
        "!echo \"\\n\"\n",
        "!cat metrics_output.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates a hybrid approach to underwater image enhancement by combining traditional color correction techniques with Real-ESRGAN for detail enhancement. The pipeline effectively addresses underwater imaging challenges such as color distortion and low contrast, producing visually appealing results. The evaluation metrics provide quantitative insights into the improvement achieved at each stage.\n",
        "\n",
        "**Next Steps**:\n",
        "- Experiment with different `CONFIG` parameters (e.g., `enhancement_strength`, `gimfilt_radius`) to optimize results for specific underwater conditions.\n",
        "- Adjust the `outscale` parameter in Real-ESRGAN for upscaling if higher resolution is desired."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
